{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfphPKxpzwgf"
      },
      "source": [
        "**This notebook was developed for the project of Deep Learning & Applied AI @Sapienza [2022/2023]**\n",
        "\n",
        "**Task**: Students will be required to compare the source separation music performance of\n",
        "the LQ-VAE model and the LASS model by re-training both models using publicly\n",
        "available datasets. They will then train a model with a loss function as in LQ-VAE, but\n",
        "using the technique of counting occurrences in the model codebook at inference time, as\n",
        "is done in LASS. The project aims to assess whether this hybrid approach can lead to\n",
        "better separation performance while maintaining efficiency at inference time.\n",
        "\n",
        "I could not achieve this task with my own hardware, the following code is strucutred to run on **Google Colab**'s T4 GPU, the service offered is extremely useful however there are time restrictions (around 3 hours per day).\n",
        "\n",
        "The project consists of three models:\n",
        "\n",
        "1.   [LQVAE](https://github.com/michelemancusi/LQVAE-separation)  - [paper](https://arxiv.org/abs/2110.05313)\n",
        "2.   [LASS](https://github.com/gladia-research-group/latent-autoregressive-source-separation)   - [paper](https://arxiv.org/abs/2301.08562)\n",
        "3.   [HYBRID](https://github.com/Pieroni1704202/LQVAE-LASS-hybrid/tree/main)     (LASS+LQVAE)\n",
        "\n",
        "All models leverage their architecture from the paper [Jukebox: A Generative Model for Music](https://arxiv.org/abs/2005.00341).\n",
        "\n",
        "One of the first challenges was correctly installing the environment for Jukebox. A lower version of Python is required to run the code of all the models, usually this is easily done with a conda environment, however, Google Colab does not fully support the use of conda environments. One way to address the issue was to install an earlier version of Miniconda, which included the desired version of Python.\n",
        "\n",
        "The data used to train the models is from [Synthesized Lakh (Slakh) Dataset](http://www.slakh.com/). The instruments used are bass and drums. From the entire dataset only 600 songs (22Khz) were extracted, 300 for bass and another 300 for drums, and then they were mixed pairwise to form 300 mixtures, this simple process can be found in the code *'slakh_scrape.py'*. The mixtures and sources (bass and drums) were finally divided into 210 for train and 90 for test. The reduced number of samples is due to the lack of computational resources.\n",
        "\n",
        "Once the training and evaluation of LASS and LQVAE were completed, the transition to building the hybrid model occurred. The model includes a VQ-VAE with an enforced post-quantization linearization on its loss, imposing an algebraic structure on the latent space, as in LQVAE. However the likelihood will not be modeled through a Ïƒ-isotropic Gaussian. Instead, similar to LASS, it will be modeled through discrete conditionals.  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGsfe6-R45lk"
      },
      "source": [
        "## MPI and Conda installation ðŸ’»"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crap_fWQoYC5"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt install mpich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jarg_yx_62oA"
      },
      "outputs": [],
      "source": [
        "%env PYTHONPATH="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDgCLNGTFh7l"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-py37_4.12.0-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG8L8j-qGtW7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7TeLKBsGynE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grBFNwfOFty7"
      },
      "outputs": [],
      "source": [
        "!which conda # should return /usr/local/bin/conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Dzo8YwFwOc"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV042DIGAVpA"
      },
      "source": [
        "## Jukebox-environment ðŸ‘·"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DztIDFExGH1U"
      },
      "outputs": [],
      "source": [
        "!conda install mpi4py==3.0.3 -y\n",
        "!pip install ffmpeg-python==0.2.0\n",
        "!conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0 -c pytorch -y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X2B_yBk-12G"
      },
      "source": [
        "The project was developed on Google Colab, Google Drive functions as it's disk space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TpLkNDwJZIM",
        "outputId": "39ca2ec0-7275-4910-bd1c-3d5c446fbd36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "GDRIVE_DIR = '/content/drive'\n",
        "\n",
        "drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWS3DW9CRgV0"
      },
      "source": [
        "**Run this cell to select either LASS, LQVAE, or HYBRID**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPSmgddXJigy",
        "outputId": "df038cc6-1985-4cb7-e973-7070e1da46f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation-main/lass_audio\n"
          ]
        }
      ],
      "source": [
        "# %cd '/content/drive/MyDrive/Deep_Learning/LQVAE-LASS-hybrid'\n",
        "\n",
        "############### OR\n",
        "\n",
        "# %cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation'\n",
        "\n",
        "############### OR\n",
        "\n",
        "%cd '/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation/lass_audio'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ritB5J5e_Syw"
      },
      "source": [
        "Install the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDQrnwSLIPvX"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zriLFyXf5nCJ"
      },
      "source": [
        "Install the selected jukebox implementation selected above ðŸŽ¶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_bXYsUF5MCI"
      },
      "outputs": [],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM7zVGEpLyG5"
      },
      "outputs": [],
      "source": [
        "!pip install av==8.1.0\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPKVw1BS5xmR"
      },
      "source": [
        "Install and login WANDB âš–"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEBgFr3gsOz7"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O2eGPfStSi8"
      },
      "outputs": [],
      "source": [
        "%env WANDB__EXECUTABLE=/usr/local/bin/python\n",
        "%env WANDB_API_KEY='################################'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHGlNKJAsWRj"
      },
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_8iYMABo6BU"
      },
      "source": [
        "# 1.LQVAE ðŸ”µ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DsbUyKboVi8"
      },
      "source": [
        "## Lqvae train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBE9ugVFMnh8"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python jukebox/train.py --hps=vqvae --sample_length=131072 --bs=2 --audio_files_dir=../data/train/mix --labels=False --train --test --aug_shift --aug_blend --name=lq_vae --test_audio_files_dir=../data/test/mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8ZULaz49_pZ"
      },
      "source": [
        "## Prior train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjCyU9so8U8"
      },
      "source": [
        "LQVAE - PRIOR - BASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Pk0ANzfo-oZ"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=pior_source --audio_files_dir=../data/train/bass --test_audio_files_dir=../data/test/bass --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/lq_vae/checkpoint_step_19160.pth.tar --restore_prior=./logs/pior_source/checkpoint_latest.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhpGCNvwmiy9"
      },
      "source": [
        "LQVAE - PRIOR - DRUMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5D18Cejmk-s"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=prior_drums --audio_files_dir=../data/train/drums --test_audio_files_dir=../data/test/drums --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/lq_vae/checkpoint_step_19160.pth.tar --restore_prior=./logs/prior_drums/checkpoint_latest.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDRkyAGrVTFO"
      },
      "source": [
        "## Codebook precalc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnAOzgTJVpT3"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation/script'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCaCu_LxVTmW"
      },
      "outputs": [],
      "source": [
        "!python codebook_precalc.py --save_path=../logs/codebook_sum_precalc.pt --restore_vqvae=../logs/lq_vae/checkpoint_step_19160.pth.tar --raw_to_tokens=64 --l_bins=2048 --sample_rate=22050 --commit=1.0 --emb_width=64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_QaUBls-Ioq"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SEpGBTfS0bJ"
      },
      "source": [
        " ### Bayesian Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfItulQ6WuTJ"
      },
      "outputs": [],
      "source": [
        "!pip install ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNqr5w0Tno5",
        "outputId": "c449d4b3-1205-4a3b-ade5-6e69aa6461d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master/script\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation/script'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH_UWYs7S2DH"
      },
      "outputs": [],
      "source": [
        "!python bayesian_inference.py --shift=5 --path_1=../../data/test/drums/Track00001_1.wav --path_2=../../data/test/bass/Track00001_1.wav --restore_vqvae=../logs/lq_vae/checkpoint_step_19160.pth.tar --restore_priors '../logs/prior_drums/checkpoint_latest.pth.tar' '../logs/pior_source/checkpoint_latest.pth.tar' --sum_codebook=../logs/codebook_sum_precalc.pt --save_path ./results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0D548JBBtj6"
      },
      "source": [
        "### Bayesian test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLgQJ0CY_y2n"
      },
      "source": [
        "This sequence of cells runs the evaluation of LQVAE: from twenty mixtures a single chunk of three seconds is extracted, this chunk is then separated using the method described in this [paper](https://arxiv.org/abs/2110.05313). To evaluate the results the generated sources are compared to the originals through Signal to Distortion Ratios, this metric is used also in both papers of LASS and LQVAE.\n",
        "\n",
        "The lower results compared to the original can be attributed to the lower training time of the model, as said before the access to a GPU is restricted to three hours per day, this is the same reason why only twenty chunks were used to evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXtEnlUlBvcm",
        "outputId": "50dd23ae-0b05-4371-850f-a80bbd7ec406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAr9ZSETBzmY",
        "outputId": "e0c1c6f7-a5c4-46ac-b481-cca09ca97e41"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./script/bayesian_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hvLuSwSAZtq"
      },
      "source": [
        "# 2.LASS  ðŸ”´"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XU_OwFc6B_X"
      },
      "source": [
        "A downgrade of protobuf is needed before training the vqvae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OqyWwUN8FuI"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf==3.20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOSd46ZWbDFM"
      },
      "source": [
        "Install diba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hELf-BSU-xRy"
      },
      "outputs": [],
      "source": [
        "#install diba\n",
        "%cd '/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation/diba'\n",
        "!pip install .\n",
        "%cd '/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation/lass_audio'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU99GCbVbVvk"
      },
      "source": [
        "## Vqvae training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTf3Mt839Wq-"
      },
      "source": [
        "Train jukebox vqvae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F0MJ0SJRuga"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./jukebox/train.py --hps=vqvae --sample_length=131072 --bs=2 --audio_files_dir=../data/train/mix --labels=False --train --test --aug_shift --aug_blend --name=vq_vae --test_audio_files_dir=../data/test/mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yqik3NoPQNH"
      },
      "source": [
        "## Prior training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq-bEfJb1jV0"
      },
      "source": [
        "TRAIN PRIOR BASS LASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAologGz1mw-"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=lass_prior_bass --audio_files_dir=../data/train/bass --test_audio_files_dir=../data/test/bass --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/vq_vae/checkpoint_step_19160.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QkiKgxxnLwu"
      },
      "source": [
        "TRAIN PRIOR DRUMS LASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wi8EpygnNf1"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=lass_prior_drums --audio_files_dir=../data/train/drums --test_audio_files_dir=../data/test/drums --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/vq_vae/checkpoint_step_19160.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61VAmOIqPTlf"
      },
      "source": [
        "## Train Sums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LADQI63vPns3"
      },
      "source": [
        "### Copy all the sources in the same dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJZheISpUQj4"
      },
      "outputs": [],
      "source": [
        "!find /content/drive/MyDrive/Deep_Learning/data/train/drums -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/data/train_sums/drums_$(basename \"$1\")\"' _ {} \\;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLxcR6rSDB85"
      },
      "outputs": [],
      "source": [
        "!find /content/drive/MyDrive/Deep_Learning/data/train/bass -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/data/train_sums/bass_$(basename \"$1\")\"' _ {} \\;"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYttTqpFPrY4"
      },
      "source": [
        "### Run train sums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzE3XVu5P2ov"
      },
      "source": [
        "Compute an approximation of distribution of sums of latent codes in a VQ-VAE, from 9000 onward it ran out of memory and a manual restarts were required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYiuMUTdPY3K",
        "outputId": "52ac30ae-7273-4a4a-f0d0-6f6a975318ff"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./lass/train_sums.py --epochs=100  --vqvae-path=./logs/vq_vae/checkpoint_step_19160.pth.tar --audio-files-dir=../data/train_sums  --output-dir=./logs/vqvae_sum_distribution --sample-length=5.944308 --sample-rate=22050 --save-iters=250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjWlTC6S9065"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsG9TG0aEbDH"
      },
      "source": [
        "\n",
        "\n",
        "This sequence of cells runs the evaluation of LASS: from twenty mixtures a single chunk of three seconds is extracted, this chunk is then separated using the method described in this [paper](https://arxiv.org/abs/2301.08562). To evaluate the results the generated sources are compared to the originals through Signal to Distortion Ratios, this metric is used also in both papers of LASS and LQVAE.\n",
        "\n",
        "The lower results compared to the original can be attributed to the lower training time of the model, as said before the access to a GPU is restricted to three hours per day, this is the same reason why only twenty chunks were used to evaluate the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opivC8W594rA",
        "outputId": "57b84ea8-ba06-496f-bc77-c2ee3d4a9138"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./lass/separate.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4yIJmvhOpxm"
      },
      "source": [
        "# 3.HYBRID ðŸŸ£"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmpeI2ERGmb3"
      },
      "source": [
        "This model is an hybrid of LASS and LQVAE, the idea is to enforce a post-quantization linearization on the loss of the vqvae as in LQVAE and use discrete conditionals to model likelihood function as in LASS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbx5OjfyxdKe"
      },
      "source": [
        "## Copy files and run train sums"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZ21K-RPxVJP"
      },
      "outputs": [],
      "source": [
        "!lfind /content/drive/MyDrive/Deep_Learning/data/train/drums -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/data/train_sums/drums_$(basename \"$1\")\"' _ {} \\;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VAyV870GSBL"
      },
      "outputs": [],
      "source": [
        "!lfind /content/drive/MyDrive/Deep_Learning/data/train/bass -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/data/train_sums/bass_$(basename \"$1\")\"' _ {} \\;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsiAyxyjxYvF"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./lass/train_sums.py --epochs=100  --vqvae-path=./logs/lq_vae/checkpoint_step_19160.pth.tar --audio-files-dir=../data/train_sums  --output-dir=./logs/vqvae_sum_distribution --sample-length=5.944308 --sample-rate=22050 --save-iters=250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-sHfq7ZxfGE"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tMYm87hJ4oa"
      },
      "source": [
        "This sequence of cells runs the evaluation of LQVAE-LASS-hybrid: from twenty mixtures a single chunk of three seconds is extracted, this chunk is then separated. To evaluate the results the generated sources are compared to the originals through Signal to Distortion Ratios, this metric is used also in both papers of LASS and LQVAE.\n",
        "\n",
        "The lower results compared to the original can be attributed to the lower training time of the model, as said before the access to a GPU is restricted to three hours per day, this is the same reason why only twenty chunks were used to evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzMz5sPaOsPk",
        "outputId": "fe9da00d-f061-4ad9-986f-5343e8547256"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./script/bayesian_test.py"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SGsfe6-R45lk",
        "NV042DIGAVpA",
        "H_8iYMABo6BU",
        "-DsbUyKboVi8",
        "v8ZULaz49_pZ",
        "LDRkyAGrVTFO",
        "2SEpGBTfS0bJ",
        "4hvLuSwSAZtq",
        "oU99GCbVbVvk",
        "1Yqik3NoPQNH",
        "61VAmOIqPTlf",
        "LADQI63vPns3",
        "aYttTqpFPrY4",
        "UjWlTC6S9065",
        "G4yIJmvhOpxm",
        "Cbx5OjfyxdKe",
        "F-sHfq7ZxfGE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
