{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**This notebook was developed for the project of Deep Learning & Applied AI @Sapienza [2022/2023]**\n",
        "\n",
        "**Task**: Students will be required to compare the source separation music performance of\n",
        "the LQ-VAE model and the LASS model by re-training both models using publicly\n",
        "available datasets. They will then train a model with a loss function as in LQ-VAE, but\n",
        "using the technique of counting occurrences in the model codebook at inference time, as\n",
        "is done in LASS. The project aims to assess whether this hybrid approach can lead to\n",
        "better separation performance while maintaining efficiency at inference time.\n",
        "\n",
        "I could not achieve this task with my own hardware, the following code is strucutred to run on **Google Colab**'s T4 GPU, the service offered is extremely useful however there are time restrictions (around 3 hours per day).\n",
        "\n",
        "The project consists of three models:\n",
        "\n",
        "1.   [LQVAE](https://github.com/michelemancusi/LQVAE-separation)  - [paper](https://arxiv.org/abs/2110.05313)\n",
        "2.   [LASS](https://github.com/gladia-research-group/latent-autoregressive-source-separation)   - [paper](https://arxiv.org/abs/2301.08562)\n",
        "3.   [HYBRID](https://github.com/Pieroni1704202/LQVAE-LASS-hybrid/tree/main)     (LASS+LQVAE)\n",
        "\n",
        "All models leverage their architecture from the paper [Jukebox: A Generative Model for Music](https://arxiv.org/abs/2005.00341).\n",
        "\n",
        "One of the first challenges was correctly installing the environment for Jukebox. A lower version of Python is required to run the code of all the models, usually this is easily done with a conda environment, however, Google Colab does not fully support the use of conda environments. One way to address the issue was to install an earlier version of Miniconda, which included the desired version of Python.\n",
        "\n",
        "The data used to train the models is from [Synthesized Lakh (Slakh) Dataset](http://www.slakh.com/). The instruments used are bass and drums. From the entire dataset only 600 songs (22Khz) were extracted, 300 for bass and another 300 for drums, and then they were mixed pairwise to form 300 mixtures, this simple process can be found in the code *'slakh_scrape.py'*. The mixtures and sources (bass and drums) were finally divided into 210 for train and 90 for test. The reduced number of samples is due to the lack of computational resources.\n",
        "\n",
        "Once the training and evaluation of LASS and LQVAE were completed, the transition to building the hybrid model occurred. The model includes a VQ-VAE with an enforced post-quantization linearization on its loss, imposing an algebraic structure on the latent space, as in LQVAE. However the likelihood will not be modeled through a σ-isotropic Gaussian. Instead, similar to LASS, it will be modeled through discrete conditionals.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pfphPKxpzwgf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGsfe6-R45lk"
      },
      "source": [
        "## MPI and Conda installation 💻"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Crap_fWQoYC5"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt install mpich"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jarg_yx_62oA"
      },
      "outputs": [],
      "source": [
        "%env PYTHONPATH="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDgCLNGTFh7l"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-py37_4.12.0-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG8L8j-qGtW7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "_ = (sys.path\n",
        "        .append(\"/usr/local/lib/python3.7/site-packages\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7TeLKBsGynE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grBFNwfOFty7"
      },
      "outputs": [],
      "source": [
        "!which conda # should return /usr/local/bin/conda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Dzo8YwFwOc"
      },
      "outputs": [],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV042DIGAVpA"
      },
      "source": [
        "## Jukebox-environment 👷"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DztIDFExGH1U"
      },
      "outputs": [],
      "source": [
        "!conda install mpi4py==3.0.3 -y\n",
        "!pip install ffmpeg-python==0.2.0\n",
        "!conda install pytorch==1.7.1 torchvision==0.8.2 torchaudio==0.7.2 cudatoolkit=11.0 -c pytorch -y"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The project was developed on Google Colab, Google Drive functions as it's disk space."
      ],
      "metadata": {
        "id": "8X2B_yBk-12G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4TpLkNDwJZIM",
        "outputId": "39ca2ec0-7275-4910-bd1c-3d5c446fbd36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "GDRIVE_DIR = '/content/drive'\n",
        "\n",
        "drive.mount(GDRIVE_DIR, force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWS3DW9CRgV0"
      },
      "source": [
        "**Run this cell to select either LASS, LQVAE, or HYBRID**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPSmgddXJigy",
        "outputId": "df038cc6-1985-4cb7-e973-7070e1da46f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation-main/lass_audio\n"
          ]
        }
      ],
      "source": [
        "# %cd '/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation-hybrid/LQVAE-LASS'\n",
        "\n",
        "############### OR\n",
        "\n",
        "# %cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master'\n",
        "\n",
        "############### OR\n",
        "\n",
        "%cd '/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation-main/lass_audio'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the required libraries"
      ],
      "metadata": {
        "id": "ritB5J5e_Syw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDQrnwSLIPvX"
      },
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zriLFyXf5nCJ"
      },
      "source": [
        "Install the selected jukebox implementation selected above 🎶"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_bXYsUF5MCI"
      },
      "outputs": [],
      "source": [
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YM7zVGEpLyG5"
      },
      "outputs": [],
      "source": [
        "!pip install av==8.1.0\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPKVw1BS5xmR"
      },
      "source": [
        "Install and login WANDB ⚖"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEBgFr3gsOz7"
      },
      "outputs": [],
      "source": [
        "!pip install wandb -qU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1O2eGPfStSi8"
      },
      "outputs": [],
      "source": [
        "%env WANDB__EXECUTABLE=/usr/local/bin/python\n",
        "%env WANDB_API_KEY=0b7b7a397718db89538438e8adf14820148254e7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHGlNKJAsWRj"
      },
      "outputs": [],
      "source": [
        "!wandb login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_8iYMABo6BU"
      },
      "source": [
        "# 1.LQVAE 🔵"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DsbUyKboVi8"
      },
      "source": [
        "## Lqvae train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBE9ugVFMnh8"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python jukebox/train.py --hps=vqvae --sample_length=131072 --bs=2 --audio_files_dir=../../train/mix --labels=False --train --test --aug_shift --aug_blend --name=lq_vae --test_audio_files_dir=../../test/mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8ZULaz49_pZ"
      },
      "source": [
        "## Prior train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pjCyU9so8U8"
      },
      "source": [
        "LQVAE - PRIOR - BASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Pk0ANzfo-oZ"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=pior_source --audio_files_dir=../../train/bass --test_audio_files_dir=../../test/bass --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/lq_vae/checkpoint_step_19160.pth.tar --restore_prior=./logs/pior_source/checkpoint_latest.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhpGCNvwmiy9"
      },
      "source": [
        "LQVAE - PRIOR - DRUMS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5D18Cejmk-s"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=prior_drums --audio_files_dir=../../train/drums --test_audio_files_dir=../../test/drums --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/lq_vae/checkpoint_step_19160.pth.tar --restore_prior=./logs/prior_drums/checkpoint_latest.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDRkyAGrVTFO"
      },
      "source": [
        "## Codebook precalc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnAOzgTJVpT3"
      },
      "outputs": [],
      "source": [
        "%cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master/script'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCaCu_LxVTmW"
      },
      "outputs": [],
      "source": [
        "!python codebook_precalc.py --save_path=../logs/codebook_sum_precalc.pt --restore_vqvae=../logs/lq_vae/checkpoint_step_19160.pth.tar --raw_to_tokens=64 --l_bins=2048 --sample_rate=22050 --commit=1.0 --emb_width=64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_QaUBls-Ioq"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SEpGBTfS0bJ"
      },
      "source": [
        " ### Bayesian Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfItulQ6WuTJ"
      },
      "outputs": [],
      "source": [
        "!pip install ipykernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgNqr5w0Tno5",
        "outputId": "c449d4b3-1205-4a3b-ade5-6e69aa6461d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master/script\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master/script'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VH_UWYs7S2DH"
      },
      "outputs": [],
      "source": [
        "!python bayesian_inference.py --shift=5 --path_1=../../../test/drums/Track00001_1.wav --path_2=../../../test/bass/Track00001_1.wav --restore_vqvae=../logs/lq_vae/checkpoint_step_19160.pth.tar --restore_priors '../logs/prior_drums/checkpoint_latest.pth.tar' '../logs/pior_source/checkpoint_latest.pth.tar' --sum_codebook=../logs/codebook_sum_precalc.pt --save_path ./results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0D548JBBtj6"
      },
      "source": [
        "### Bayesian test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sequence of cells runs the evaluation of LQVAE: from twenty mixtures a single chunk of three seconds is extracted, this chunk is then separated using the method described in this [paper](https://arxiv.org/abs/2110.05313). To evaluate the results the generated sources are compared to the originals through Signal-to-Noise Ratio, this metric is used also in both papers of LASS and LQVAE.\n",
        "\n",
        "The lower results compared to the original can be attributed to the lower training time of the model, as said before the access to a GPU is restricted to three hours per day, this is the same reason why only twenty chunks were used to evaluate the model.\n"
      ],
      "metadata": {
        "id": "bLgQJ0CY_y2n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXtEnlUlBvcm",
        "outputId": "50dd23ae-0b05-4371-850f-a80bbd7ec406"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master\n"
          ]
        }
      ],
      "source": [
        "%cd '/content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAr9ZSETBzmY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c1c6f7-a5c4-46ac-b481-cca09ca97e41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n",
            "wandb: Currently logged in as: 1704202-michpier. Use `wandb login --relogin` to force relogin\n",
            "wandb: Tracking run with wandb version 0.16.2\n",
            "wandb: Run data is saved locally in /content/drive/MyDrive/Deep_Learning/LQVAE-separation-master/LQVAE-separation-master/wandb/run-20240113_180628-lq_evaluation\n",
            "wandb: Run `wandb offline` to turn off syncing.\n",
            "wandb: Syncing run lq_evaluation\n",
            "wandb: ⭐️ View project at https://wandb.ai/1704202-michpier/DL-Project-LQVAE\n",
            "wandb: 🚀 View run at https://wandb.ai/1704202-michpier/DL-Project-LQVAE/runs/lq_evaluation\n",
            "Using cuda True\n",
            "Restored from ./logs/lq_vae/checkpoint_step_19160.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Level:2, Cond downsample:None, Raw to tokens:64, Sample length:524288\n",
            "0: Converting to fp16 params\n",
            "Restored from ./logs/prior_bass/checkpoint_latest.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Level:2, Cond downsample:None, Raw to tokens:64, Sample length:524288\n",
            "0: Converting to fp16 params\n",
            "Restored from ./logs/prior_drums/checkpoint_latest.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Found 89 instances of instrument_1\n",
            "Found 89 instances of instrument_2\n",
            "available_chunks for ('Track00001_1.wav', 'Track00001_1.wav'): 1\n",
            "available_chunks for ('Track00002_2.wav', 'Track00002_2.wav'): 1\n",
            "available_chunks for ('Track00003_3.wav', 'Track00003_3.wav'): 1\n",
            "available_chunks for ('Track00004_4.wav', 'Track00004_4.wav'): 1\n",
            "available_chunks for ('Track00005_5.wav', 'Track00005_5.wav'): 1\n",
            "available_chunks for ('Track00006_6.wav', 'Track00006_6.wav'): 1\n",
            "available_chunks for ('Track00007_7.wav', 'Track00007_7.wav'): 1\n",
            "available_chunks for ('Track00008_8.wav', 'Track00008_8.wav'): 1\n",
            "available_chunks for ('Track00009_9.wav', 'Track00009_9.wav'): 1\n",
            "available_chunks for ('Track00010_10.wav', 'Track00010_10.wav'): 1\n",
            "available_chunks for ('Track00011_11.wav', 'Track00011_11.wav'): 1\n",
            "available_chunks for ('Track00012_12.wav', 'Track00012_12.wav'): 1\n",
            "available_chunks for ('Track00012_13.wav', 'Track00013_13.wav'): 1\n",
            "available_chunks for ('Track00013_14.wav', 'Track00014_14.wav'): 1\n",
            "available_chunks for ('Track00013_15.wav', 'Track00015_15.wav'): 1\n",
            "available_chunks for ('Track00014_16.wav', 'Track00016_16.wav'): 1\n",
            "available_chunks for ('Track00015_17.wav', 'Track00017_17.wav'): 1\n",
            "available_chunks for ('Track00018_19.wav', 'Track00019_19.wav'): 1\n",
            "available_chunks for ('Track00018_20.wav', 'Track00020_20.wav'): 1\n",
            "available_chunks for ('Track00019_21.wav', 'Track00021_21.wav'): 1\n",
            "available_chunks for ('Track00020_22.wav', 'Track00022_22.wav'): 1\n",
            "available_chunks for ('Track00023_23.wav', 'Track00023_23.wav'): 1\n",
            "available_chunks for ('Track00024_24.wav', 'Track00024_24.wav'): 1\n",
            "available_chunks for ('Track00024_25.wav', 'Track00025_25.wav'): 1\n",
            "available_chunks for ('Track00024_26.wav', 'Track00026_26.wav'): 1\n",
            "available_chunks for ('Track00025_27.wav', 'Track00027_27.wav'): 1\n",
            "available_chunks for ('Track00026_28.wav', 'Track00028_28.wav'): 1\n",
            "available_chunks for ('Track00027_29.wav', 'Track00029_29.wav'): 1\n",
            "available_chunks for ('Track00028_30.wav', 'Track00030_30.wav'): 1\n",
            "available_chunks for ('Track00028_31.wav', 'Track00031_31.wav'): 1\n",
            "available_chunks for ('Track00030_32.wav', 'Track00032_32.wav'): 1\n",
            "available_chunks for ('Track00031_33.wav', 'Track00033_33.wav'): 1\n",
            "available_chunks for ('Track00032_34.wav', 'Track00034_34.wav'): 1\n",
            "available_chunks for ('Track00033_35.wav', 'Track00035_35.wav'): 1\n",
            "available_chunks for ('Track00034_36.wav', 'Track00036_36.wav'): 1\n",
            "available_chunks for ('Track00035_37.wav', 'Track00037_37.wav'): 1\n",
            "available_chunks for ('Track00036_38.wav', 'Track00038_38.wav'): 1\n",
            "available_chunks for ('Track00037_39.wav', 'Track00039_39.wav'): 1\n",
            "available_chunks for ('Track00038_40.wav', 'Track00040_40.wav'): 1\n",
            "available_chunks for ('Track00039_41.wav', 'Track00041_41.wav'): 1\n",
            "available_chunks for ('Track00040_42.wav', 'Track00042_42.wav'): 1\n",
            "available_chunks for ('Track00040_43.wav', 'Track00043_43.wav'): 1\n",
            "available_chunks for ('Track00040_44.wav', 'Track00044_44.wav'): 1\n",
            "available_chunks for ('Track00040_45.wav', 'Track00045_45.wav'): 1\n",
            "available_chunks for ('Track00041_46.wav', 'Track00046_46.wav'): 1\n",
            "available_chunks for ('Track00042_47.wav', 'Track00047_47.wav'): 1\n",
            "available_chunks for ('Track00043_48.wav', 'Track00048_48.wav'): 1\n",
            "available_chunks for ('Track00043_49.wav', 'Track00050_49.wav'): 1\n",
            "available_chunks for ('Track00044_50.wav', 'Track00051_50.wav'): 1\n",
            "available_chunks for ('Track00045_51.wav', 'Track00052_51.wav'): 1\n",
            "available_chunks for ('Track00046_52.wav', 'Track00053_52.wav'): 1\n",
            "available_chunks for ('Track00046_53.wav', 'Track00054_53.wav'): 1\n",
            "available_chunks for ('Track00047_54.wav', 'Track00055_54.wav'): 1\n",
            "available_chunks for ('Track00048_55.wav', 'Track00056_55.wav'): 1\n",
            "available_chunks for ('Track00048_56.wav', 'Track00057_56.wav'): 1\n",
            "available_chunks for ('Track00050_57.wav', 'Track00058_57.wav'): 1\n",
            "available_chunks for ('Track00051_58.wav', 'Track00059_58.wav'): 1\n",
            "available_chunks for ('Track00052_59.wav', 'Track00060_59.wav'): 1\n",
            "available_chunks for ('Track00053_60.wav', 'Track00061_60.wav'): 1\n",
            "available_chunks for ('Track00054_61.wav', 'Track00062_61.wav'): 1\n",
            "available_chunks for ('Track00055_62.wav', 'Track00063_62.wav'): 1\n",
            "available_chunks for ('Track00059_63.wav', 'Track00064_63.wav'): 1\n",
            "available_chunks for ('Track00060_64.wav', 'Track00065_64.wav'): 1\n",
            "available_chunks for ('Track00061_65.wav', 'Track00066_65.wav'): 1\n",
            "available_chunks for ('Track00063_66.wav', 'Track00067_66.wav'): 1\n",
            "available_chunks for ('Track00064_67.wav', 'Track00068_67.wav'): 1\n",
            "available_chunks for ('Track00065_68.wav', 'Track00069_68.wav'): 1\n",
            "available_chunks for ('Track00066_69.wav', 'Track00070_69.wav'): 1\n",
            "available_chunks for ('Track00067_70.wav', 'Track00071_70.wav'): 1\n",
            "available_chunks for ('Track00068_71.wav', 'Track00072_71.wav'): 1\n",
            "available_chunks for ('Track00069_72.wav', 'Track00073_72.wav'): 1\n",
            "available_chunks for ('Track00071_73.wav', 'Track00074_73.wav'): 1\n",
            "available_chunks for ('Track00072_74.wav', 'Track00075_74.wav'): 1\n",
            "available_chunks for ('Track00073_75.wav', 'Track00076_75.wav'): 1\n",
            "available_chunks for ('Track00074_76.wav', 'Track00078_76.wav'): 1\n",
            "available_chunks for ('Track00074_77.wav', 'Track00079_77.wav'): 1\n",
            "available_chunks for ('Track00074_78.wav', 'Track00080_78.wav'): 1\n",
            "available_chunks for ('Track00075_79.wav', 'Track00081_79.wav'): 1\n",
            "available_chunks for ('Track00076_80.wav', 'Track00082_80.wav'): 1\n",
            "available_chunks for ('Track00078_81.wav', 'Track00083_81.wav'): 1\n",
            "available_chunks for ('Track00079_82.wav', 'Track00084_82.wav'): 1\n",
            "available_chunks for ('Track00079_83.wav', 'Track00085_83.wav'): 1\n",
            "available_chunks for ('Track00080_84.wav', 'Track00086_84.wav'): 1\n",
            "available_chunks for ('Track00081_85.wav', 'Track00087_85.wav'): 1\n",
            "available_chunks for ('Track00082_86.wav', 'Track00088_86.wav'): 1\n",
            "available_chunks for ('Track00082_87.wav', 'Track00089_87.wav'): 1\n",
            "available_chunks for ('Track00083_88.wav', 'Track00090_88.wav'): 1\n",
            "available_chunks for ('Track00084_89.wav', 'Track00091_89.wav'): 1\n",
            "available_chunks for ('Track00085_90.wav', 'Track00092_90.wav'): 1\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 1 out of 89\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 46.36it/s]\n",
            "SDR GT: sdr0=4.179442405700684, sdr1=8.693485260009766\n",
            "SDR REAL: sdr0=4.361541748046875, sdr1=7.554854869842529\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 2 out of 89\n",
            "1024/1024 [04:13<00:00,  4.04it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.17it/s]\n",
            "SDR GT: sdr0=2.7418110370635986, sdr1=4.3317437171936035\n",
            "SDR REAL: sdr0=2.8407559394836426, sdr1=4.284640312194824\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 3 out of 89\n",
            "1024/1024 [04:14<00:00,  4.02it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.89it/s]\n",
            "SDR GT: sdr0=4.939899444580078, sdr1=5.423475742340088\n",
            "SDR REAL: sdr0=4.828057765960693, sdr1=4.807799816131592\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 4 out of 89\n",
            "1024/1024 [04:15<00:00,  4.01it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.90it/s]\n",
            "SDR GT: sdr0=4.224868297576904, sdr1=2.753365993499756\n",
            "SDR REAL: sdr0=4.141334056854248, sdr1=3.0803940296173096\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 5 out of 89\n",
            "1024/1024 [04:15<00:00,  4.01it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 37.85it/s]\n",
            "SDR GT: sdr0=3.3291213512420654, sdr1=3.2787349224090576\n",
            "SDR REAL: sdr0=3.543346405029297, sdr1=3.154932737350464\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 6 out of 89\n",
            "1024/1024 [04:14<00:00,  4.02it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.77it/s]\n",
            "SDR GT: sdr0=5.986362457275391, sdr1=7.098541259765625\n",
            "SDR REAL: sdr0=5.806936264038086, sdr1=6.710933208465576\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 7 out of 89\n",
            "1024/1024 [04:15<00:00,  4.01it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 45.38it/s]\n",
            "SDR GT: sdr0=4.589724063873291, sdr1=6.342961311340332\n",
            "SDR REAL: sdr0=4.616700649261475, sdr1=6.1687774658203125\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 8 out of 89\n",
            "1024/1024 [04:13<00:00,  4.04it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.44it/s]\n",
            "SDR GT: sdr0=3.2750906944274902, sdr1=6.910109996795654\n",
            "SDR REAL: sdr0=3.2966020107269287, sdr1=6.309829235076904\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 9 out of 89\n",
            "1024/1024 [04:14<00:00,  4.03it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.15it/s]\n",
            "SDR GT: sdr0=4.126648902893066, sdr1=8.312403678894043\n",
            "SDR REAL: sdr0=4.119132995605469, sdr1=7.742904186248779\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 10 out of 89\n",
            "1024/1024 [04:15<00:00,  4.00it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 45.58it/s]\n",
            "SDR GT: sdr0=4.2261834144592285, sdr1=4.854317665100098\n",
            "SDR REAL: sdr0=4.219785213470459, sdr1=4.326836109161377\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 11 out of 89\n",
            "1024/1024 [04:18<00:00,  3.96it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 45.92it/s]\n",
            "SDR GT: sdr0=2.998246431350708, sdr1=3.538238286972046\n",
            "SDR REAL: sdr0=3.2800583839416504, sdr1=3.7173757553100586\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 12 out of 89\n",
            "1024/1024 [04:13<00:00,  4.04it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.19it/s]\n",
            "SDR GT: sdr0=4.352811336517334, sdr1=3.2150514125823975\n",
            "SDR REAL: sdr0=4.27894926071167, sdr1=3.1591198444366455\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 13 out of 89\n",
            "1024/1024 [04:14<00:00,  4.02it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.13it/s]\n",
            "SDR GT: sdr0=2.298947334289551, sdr1=5.218552589416504\n",
            "SDR REAL: sdr0=2.342320203781128, sdr1=4.598633766174316\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 14 out of 89\n",
            "1024/1024 [04:12<00:00,  4.05it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 43.02it/s]\n",
            "SDR GT: sdr0=3.109386682510376, sdr1=5.963248252868652\n",
            "SDR REAL: sdr0=3.503438711166382, sdr1=5.067477226257324\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 15 out of 89\n",
            "1024/1024 [04:13<00:00,  4.03it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.95it/s]\n",
            "SDR GT: sdr0=2.799171209335327, sdr1=5.7868266105651855\n",
            "SDR REAL: sdr0=3.1799635887145996, sdr1=5.339256763458252\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 16 out of 89\n",
            "1024/1024 [04:15<00:00,  4.01it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 45.14it/s]\n",
            "SDR GT: sdr0=2.09676194190979, sdr1=7.158407211303711\n",
            "SDR REAL: sdr0=2.3936002254486084, sdr1=7.014862537384033\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 17 out of 89\n",
            "1024/1024 [04:17<00:00,  3.97it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 37.75it/s]\n",
            "SDR GT: sdr0=3.223803997039795, sdr1=6.662829399108887\n",
            "SDR REAL: sdr0=3.391585111618042, sdr1=6.191354274749756\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 18 out of 89\n",
            "1024/1024 [04:16<00:00,  3.99it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.38it/s]\n",
            "SDR GT: sdr0=2.301394462585449, sdr1=5.433477401733398\n",
            "SDR REAL: sdr0=2.225069761276245, sdr1=5.657538414001465\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 19 out of 89\n",
            "1024/1024 [04:13<00:00,  4.04it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.45it/s]\n",
            "SDR GT: sdr0=1.580217719078064, sdr1=5.155524253845215\n",
            "SDR REAL: sdr0=1.6077204942703247, sdr1=5.144106388092041\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 20 out of 89\n",
            "1024/1024 [04:12<00:00,  4.05it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.56it/s]\n",
            "SDR GT: sdr0=3.8386659622192383, sdr1=5.6419196128845215\n",
            "SDR REAL: sdr0=3.998180866241455, sdr1=5.535437107086182\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 21 out of 89\n",
            "1024/1024 [04:14<00:00,  4.03it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.44it/s]\n",
            "SDR GT: sdr0=1.5093046426773071, sdr1=6.034045696258545\n",
            "SDR REAL: sdr0=1.854047179222107, sdr1=6.196917533874512\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 22 out of 89\n",
            "1024/1024 [04:12<00:00,  4.06it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.37it/s]\n",
            "SDR GT: sdr0=4.163543224334717, sdr1=5.048672676086426\n",
            "SDR REAL: sdr0=4.10677433013916, sdr1=5.027676105499268\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 23 out of 89\n",
            "1024/1024 [04:11<00:00,  4.07it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.80it/s]\n",
            "SDR GT: sdr0=3.5576086044311523, sdr1=7.972128868103027\n",
            "SDR REAL: sdr0=3.440275192260742, sdr1=7.072495937347412\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 24 out of 89\n",
            "1024/1024 [04:13<00:00,  4.03it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 35.59it/s]\n",
            "SDR GT: sdr0=1.6960735321044922, sdr1=5.089522838592529\n",
            "SDR REAL: sdr0=1.9701226949691772, sdr1=4.891844749450684\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 25 out of 89\n",
            "1024/1024 [04:12<00:00,  4.06it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 36.52it/s]\n",
            "SDR GT: sdr0=3.0547080039978027, sdr1=6.642061233520508\n",
            "SDR REAL: sdr0=3.041337728500366, sdr1=5.743576526641846\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 26 out of 89\n",
            "1024/1024 [04:19<00:00,  3.95it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 38.35it/s]\n",
            "SDR GT: sdr0=2.095365524291992, sdr1=4.973972797393799\n",
            "SDR REAL: sdr0=2.468308210372925, sdr1=4.8004584312438965\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 27 out of 89\n",
            "1024/1024 [04:13<00:00,  4.04it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 45.27it/s]\n",
            "SDR GT: sdr0=2.583355188369751, sdr1=5.823922634124756\n",
            "SDR REAL: sdr0=2.9529550075531006, sdr1=5.52724552154541\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 28 out of 89\n",
            "1024/1024 [04:12<00:00,  4.05it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 37.55it/s]\n",
            "SDR GT: sdr0=1.3615096807479858, sdr1=6.633676052093506\n",
            "SDR REAL: sdr0=1.5959193706512451, sdr1=6.143789768218994\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 29 out of 89\n",
            "1024/1024 [04:14<00:00,  4.02it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 44.76it/s]\n",
            "SDR GT: sdr0=6.545968532562256, sdr1=6.329308986663818\n",
            "SDR REAL: sdr0=6.26048469543457, sdr1=5.839972496032715\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 30 out of 89\n",
            "1024/1024 [04:13<00:00,  4.05it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:01<00:00, 45.69it/s]\n",
            "SDR GT: sdr0=2.529740571975708, sdr1=5.411896228790283\n",
            "SDR REAL: sdr0=2.5899534225463867, sdr1=5.444502353668213\n",
            "orig1: torch.Size([1, 65536])\n",
            "Track mix 31 out of 89\n",
            "432/1024 [01:47<02:20,  4.23it/s][mpiexec@f5cac22753d2] Sending Ctrl-C to processes as requested\n",
            "[mpiexec@f5cac22753d2] Press Ctrl-C again to force abort\n",
            "Ctrl-C caught... cleaning up processes\n",
            "[proxy:0:0@f5cac22753d2] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:878): assert (!closed) failed\n",
            "[proxy:0:0@f5cac22753d2] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:77): callback returned error status\n",
            "[proxy:0:0@f5cac22753d2] main (pm/pmiserv/pmip.c:200): demux engine error waiting for event\n",
            "[mpiexec@f5cac22753d2] HYDT_bscu_wait_for_completion (tools/bootstrap/utils/bscu_wait.c:75): one of the processes terminated badly; aborting\n",
            "[mpiexec@f5cac22753d2] HYDT_bsci_wait_for_completion (tools/bootstrap/src/bsci_wait.c:22): launcher returned error waiting for completion\n",
            "[mpiexec@f5cac22753d2] HYD_pmci_wait_for_completion (pm/pmiserv/pmiserv_pmci.c:215): launcher returned error waiting for completion\n",
            "[mpiexec@f5cac22753d2] main (ui/mpich/mpiexec.c:336): process manager error waiting for completion\n"
          ]
        }
      ],
      "source": [
        "!mpiexec -n 1 python ./script/bayesian_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hvLuSwSAZtq"
      },
      "source": [
        "# 2.LASS  🔴"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XU_OwFc6B_X"
      },
      "source": [
        "A downgrade of protobuf is needed before training the vqvae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OqyWwUN8FuI"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf==3.20"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install diba"
      ],
      "metadata": {
        "id": "pOSd46ZWbDFM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hELf-BSU-xRy"
      },
      "outputs": [],
      "source": [
        "#install diba\n",
        "%cd '/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation-main/diba'\n",
        "!pip install .\n",
        "%cd '/content/drive/MyDrive/Deep_Learning/latent-autoregressive-source-separation-main/lass_audio'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oU99GCbVbVvk"
      },
      "source": [
        "## Vqvae training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTf3Mt839Wq-"
      },
      "source": [
        "Train jukebox vqvae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-F0MJ0SJRuga"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./jukebox/train.py --hps=vqvae --sample_length=131072 --bs=2 --audio_files_dir=../../train/mix --labels=False --train --test --aug_shift --aug_blend --name=vq_vae --test_audio_files_dir=../../test/mix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Yqik3NoPQNH"
      },
      "source": [
        "## Prior training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq-bEfJb1jV0"
      },
      "source": [
        "TRAIN PRIOR BASS LASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAologGz1mw-"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=lass_prior_bass --audio_files_dir=../../train/bass --test_audio_files_dir=../../test/bass --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/vq_vae/checkpoint_step_19160.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QkiKgxxnLwu"
      },
      "source": [
        "TRAIN PRIOR DRUMS LASS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wi8EpygnNf1"
      },
      "outputs": [],
      "source": [
        "!mpiexec -n 1 python ./jukebox/train.py --hps=vqvae,small_prior,all_fp16,cpu_ema --name=lass_prior_drums --audio_files_dir=../../train/drums --test_audio_files_dir=../../test/drums --labels=False --train --test --aug_shift --aug_blend --prior --levels=3 --level=2 --weight_decay=0.01 --min_duration=24 --sample_length=524288 --bs=8 --n_ctx=8192 --sample=True --restore_vqvae=./logs/vq_vae/checkpoint_step_19160.pth.tar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61VAmOIqPTlf"
      },
      "source": [
        "## Train Sums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LADQI63vPns3"
      },
      "source": [
        "### Copy all the sources in the same dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJZheISpUQj4"
      },
      "outputs": [],
      "source": [
        "!find /content/drive/MyDrive/Deep_Learning/train/drums -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/train_sums/drums_$(basename \"$1\")\"' _ {} \\;"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/drive/MyDrive/Deep_Learning/train/bass -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/train_sums/bass_$(basename \"$1\")\"' _ {} \\;"
      ],
      "metadata": {
        "id": "dLxcR6rSDB85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYttTqpFPrY4"
      },
      "source": [
        "### Run train sums"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzE3XVu5P2ov"
      },
      "source": [
        "Compute an approximation of distribution of sums of latent codes in a VQ-VAE, from 9000 onward it ran out of memory and a manual restarts were required."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYiuMUTdPY3K",
        "outputId": "52ac30ae-7273-4a4a-f0d0-6f6a975318ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n",
            "\r  0%|          | 0/2192 [00:00<?, ?it/s]Using cuda True\n",
            "Restored from ./logs/vq_vae/checkpoint_step_11496.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "0: Found 420 files. Getting durations\n",
            "0: self.sr=22050, min: 5.954308, max: inf\n",
            "0: Keeping 420 of 420 files\n",
            "100%|██████████| 2192/2192 [34:51<00:00,  1.05it/s]\n",
            "100%|██████████| 2192/2192 [36:22<00:00,  1.00it/s]\n",
            "100%|██████████| 2192/2192 [37:19<00:00,  1.02s/it]\n",
            "100%|██████████| 2192/2192 [37:45<00:00,  1.03s/it]\n",
            "100%|██████████| 2192/2192 [37:51<00:00,  1.04s/it]\n",
            "  2%|▏         | 39/2192 [00:43<33:28,  1.07it/s]"
          ]
        }
      ],
      "source": [
        "!mpiexec -n 1 python ./lass/train_sums.py --epochs=100  --vqvae-path=./logs/vq_vae/checkpoint_step_19160.pth.tar --audio-files-dir=../../train_sums  --output-dir=./logs/vqvae_sum_distribution --sample-length=5.944308 --sample-rate=22050 --save-iters=250"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjWlTC6S9065"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This sequence of cells runs the evaluation of LASS: from twenty mixtures a single chunk of three seconds is extracted, this chunk is then separated using the method described in this [paper](https://arxiv.org/abs/2301.08562). To evaluate the results the generated sources are compared to the originals through Signal-to-Noise Ratio, this metric is used also in both papers of LASS and LQVAE.\n",
        "\n",
        "The lower results compared to the original can be attributed to the lower training time of the model, as said before the access to a GPU is restricted to three hours per day, this is the same reason why only twenty chunks were used to evaluate the model.\n"
      ],
      "metadata": {
        "id": "KsG9TG0aEbDH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opivC8W594rA",
        "outputId": "57b84ea8-ba06-496f-bc77-c2ee3d4a9138"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n",
            "/usr/local/lib/python3.7/site-packages/sparse/_umath.py:542: RuntimeWarning: divide by zero encountered in log\n",
            "  *np.broadcast_arrays(*zero_args), dtype=self.dtype, **self.kwargs\n",
            "100%|██████████| 1024/1024 [03:09<00:00,  5.40it/s]\n",
            "100%|██████████| 1024/1024 [03:20<00:00,  5.11it/s]\n",
            "Connecting to master_addr: 127.0.0.1\n",
            "Using cuda True\n",
            "Restored from ./logs/vq_vae/checkpoint_step_19160.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Level:2, Cond downsample:None, Raw to tokens:64, Sample length:524288\n",
            "0: Converting to fp16 params\n",
            "Restored from ./logs/lass_prior_drums/checkpoint_latest.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Level:2, Cond downsample:None, Raw to tokens:64, Sample length:524288\n",
            "0: Converting to fp16 params\n",
            "Restored from ./logs/lass_prior_bass/checkpoint_latest.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Found 89 instances of instrument_1\n",
            "Found 89 instances of instrument_2\n",
            "available_chunks for ('Track00001_1.wav', 'Track00001_1.wav'): 1\n",
            "available_chunks for ('Track00002_2.wav', 'Track00002_2.wav'): 1\n",
            "available_chunks for ('Track00003_3.wav', 'Track00003_3.wav'): 1\n",
            "available_chunks for ('Track00004_4.wav', 'Track00004_4.wav'): 1\n",
            "available_chunks for ('Track00005_5.wav', 'Track00005_5.wav'): 1\n",
            "available_chunks for ('Track00006_6.wav', 'Track00006_6.wav'): 1\n",
            "available_chunks for ('Track00007_7.wav', 'Track00007_7.wav'): 1\n",
            "available_chunks for ('Track00008_8.wav', 'Track00008_8.wav'): 1\n",
            "available_chunks for ('Track00009_9.wav', 'Track00009_9.wav'): 1\n",
            "available_chunks for ('Track00010_10.wav', 'Track00010_10.wav'): 1\n",
            "available_chunks for ('Track00011_11.wav', 'Track00011_11.wav'): 1\n",
            "available_chunks for ('Track00012_12.wav', 'Track00012_12.wav'): 1\n",
            "available_chunks for ('Track00013_13.wav', 'Track00012_13.wav'): 1\n",
            "available_chunks for ('Track00014_14.wav', 'Track00013_14.wav'): 1\n",
            "available_chunks for ('Track00015_15.wav', 'Track00013_15.wav'): 1\n",
            "available_chunks for ('Track00016_16.wav', 'Track00014_16.wav'): 1\n",
            "available_chunks for ('Track00017_17.wav', 'Track00015_17.wav'): 1\n",
            "available_chunks for ('Track00019_19.wav', 'Track00018_19.wav'): 1\n",
            "available_chunks for ('Track00020_20.wav', 'Track00018_20.wav'): 1\n",
            "available_chunks for ('Track00021_21.wav', 'Track00019_21.wav'): 1\n",
            "available_chunks for ('Track00022_22.wav', 'Track00020_22.wav'): 1\n",
            "available_chunks for ('Track00023_23.wav', 'Track00023_23.wav'): 1\n",
            "available_chunks for ('Track00024_24.wav', 'Track00024_24.wav'): 1\n",
            "available_chunks for ('Track00025_25.wav', 'Track00024_25.wav'): 1\n",
            "available_chunks for ('Track00026_26.wav', 'Track00024_26.wav'): 1\n",
            "available_chunks for ('Track00027_27.wav', 'Track00025_27.wav'): 1\n",
            "available_chunks for ('Track00028_28.wav', 'Track00026_28.wav'): 1\n",
            "available_chunks for ('Track00029_29.wav', 'Track00027_29.wav'): 1\n",
            "available_chunks for ('Track00030_30.wav', 'Track00028_30.wav'): 1\n",
            "available_chunks for ('Track00031_31.wav', 'Track00028_31.wav'): 1\n",
            "available_chunks for ('Track00032_32.wav', 'Track00030_32.wav'): 1\n",
            "available_chunks for ('Track00033_33.wav', 'Track00031_33.wav'): 1\n",
            "available_chunks for ('Track00034_34.wav', 'Track00032_34.wav'): 1\n",
            "available_chunks for ('Track00035_35.wav', 'Track00033_35.wav'): 1\n",
            "available_chunks for ('Track00036_36.wav', 'Track00034_36.wav'): 1\n",
            "available_chunks for ('Track00037_37.wav', 'Track00035_37.wav'): 1\n",
            "available_chunks for ('Track00038_38.wav', 'Track00036_38.wav'): 1\n",
            "available_chunks for ('Track00039_39.wav', 'Track00037_39.wav'): 1\n",
            "available_chunks for ('Track00040_40.wav', 'Track00038_40.wav'): 1\n",
            "available_chunks for ('Track00041_41.wav', 'Track00039_41.wav'): 1\n",
            "available_chunks for ('Track00042_42.wav', 'Track00040_42.wav'): 1\n",
            "available_chunks for ('Track00043_43.wav', 'Track00040_43.wav'): 1\n",
            "available_chunks for ('Track00044_44.wav', 'Track00040_44.wav'): 1\n",
            "available_chunks for ('Track00045_45.wav', 'Track00040_45.wav'): 1\n",
            "available_chunks for ('Track00046_46.wav', 'Track00041_46.wav'): 1\n",
            "available_chunks for ('Track00047_47.wav', 'Track00042_47.wav'): 1\n",
            "available_chunks for ('Track00048_48.wav', 'Track00043_48.wav'): 1\n",
            "available_chunks for ('Track00050_49.wav', 'Track00043_49.wav'): 1\n",
            "available_chunks for ('Track00051_50.wav', 'Track00044_50.wav'): 1\n",
            "available_chunks for ('Track00052_51.wav', 'Track00045_51.wav'): 1\n",
            "available_chunks for ('Track00053_52.wav', 'Track00046_52.wav'): 1\n",
            "available_chunks for ('Track00054_53.wav', 'Track00046_53.wav'): 1\n",
            "available_chunks for ('Track00055_54.wav', 'Track00047_54.wav'): 1\n",
            "available_chunks for ('Track00056_55.wav', 'Track00048_55.wav'): 1\n",
            "available_chunks for ('Track00057_56.wav', 'Track00048_56.wav'): 1\n",
            "available_chunks for ('Track00058_57.wav', 'Track00050_57.wav'): 1\n",
            "available_chunks for ('Track00059_58.wav', 'Track00051_58.wav'): 1\n",
            "available_chunks for ('Track00060_59.wav', 'Track00052_59.wav'): 1\n",
            "available_chunks for ('Track00061_60.wav', 'Track00053_60.wav'): 1\n",
            "available_chunks for ('Track00062_61.wav', 'Track00054_61.wav'): 1\n",
            "available_chunks for ('Track00063_62.wav', 'Track00055_62.wav'): 1\n",
            "available_chunks for ('Track00064_63.wav', 'Track00059_63.wav'): 1\n",
            "available_chunks for ('Track00065_64.wav', 'Track00060_64.wav'): 1\n",
            "available_chunks for ('Track00066_65.wav', 'Track00061_65.wav'): 1\n",
            "available_chunks for ('Track00067_66.wav', 'Track00063_66.wav'): 1\n",
            "available_chunks for ('Track00068_67.wav', 'Track00064_67.wav'): 1\n",
            "available_chunks for ('Track00069_68.wav', 'Track00065_68.wav'): 1\n",
            "available_chunks for ('Track00070_69.wav', 'Track00066_69.wav'): 1\n",
            "available_chunks for ('Track00071_70.wav', 'Track00067_70.wav'): 1\n",
            "available_chunks for ('Track00072_71.wav', 'Track00068_71.wav'): 1\n",
            "available_chunks for ('Track00073_72.wav', 'Track00069_72.wav'): 1\n",
            "available_chunks for ('Track00074_73.wav', 'Track00071_73.wav'): 1\n",
            "available_chunks for ('Track00075_74.wav', 'Track00072_74.wav'): 1\n",
            "available_chunks for ('Track00076_75.wav', 'Track00073_75.wav'): 1\n",
            "available_chunks for ('Track00078_76.wav', 'Track00074_76.wav'): 1\n",
            "available_chunks for ('Track00079_77.wav', 'Track00074_77.wav'): 1\n",
            "available_chunks for ('Track00080_78.wav', 'Track00074_78.wav'): 1\n",
            "available_chunks for ('Track00081_79.wav', 'Track00075_79.wav'): 1\n",
            "available_chunks for ('Track00082_80.wav', 'Track00076_80.wav'): 1\n",
            "available_chunks for ('Track00083_81.wav', 'Track00078_81.wav'): 1\n",
            "available_chunks for ('Track00084_82.wav', 'Track00079_82.wav'): 1\n",
            "available_chunks for ('Track00085_83.wav', 'Track00079_83.wav'): 1\n",
            "available_chunks for ('Track00086_84.wav', 'Track00080_84.wav'): 1\n",
            "available_chunks for ('Track00087_85.wav', 'Track00081_85.wav'): 1\n",
            "available_chunks for ('Track00088_86.wav', 'Track00082_86.wav'): 1\n",
            "available_chunks for ('Track00089_87.wav', 'Track00082_87.wav'): 1\n",
            "available_chunks for ('Track00090_88.wav', 'Track00083_88.wav'): 1\n",
            "available_chunks for ('Track00091_89.wav', 'Track00084_89.wav'): 1\n",
            "available_chunks for ('Track00092_90.wav', 'Track00085_90.wav'): 1\n",
            "chunk 1 out of 89\n",
            "Shape di x1: torch.Size([64, 1024])\n",
            "Shape di x1: torch.Size([64, 1024])\n",
            "Shape di decoded: torch.Size([65536])\n",
            "SDR track 0:\n",
            "sdr_0:4.229710578918457\n",
            "sdr_1:1.3889888525009155\n",
            "sdr_0_max:6.263105392456055\n",
            "sdr_1_max:3.820667028427124\n",
            "sep_time: 192.89259457588196\n",
            "chunk 2 out of 89\n",
            "Shape di x1: torch.Size([64, 1024])\n",
            "Shape di x1: torch.Size([64, 1024])\n",
            "Shape di decoded: torch.Size([65536])\n",
            "SDR track 1:\n",
            "sdr_0:1.697651743888855\n",
            "sdr_1:0.5317103862762451\n",
            "sdr_0_max:4.9057159423828125\n",
            "sdr_1_max:4.522505283355713\n",
            "sep_time: 201.9349443912506\n"
          ]
        }
      ],
      "source": [
        "!mpiexec -n 1 python ./lass/separate.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.HYBRID 🟣"
      ],
      "metadata": {
        "id": "G4yIJmvhOpxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is an hybrid of LASS and LQVAE, the idea is to enforce a post-quantization linearization on the loss of the vqvae as in LQVAE and use discrete conditionals to model likelihood function as in LASS."
      ],
      "metadata": {
        "id": "VmpeI2ERGmb3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy files and run train sums"
      ],
      "metadata": {
        "id": "Cbx5OjfyxdKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!lfind /content/drive/MyDrive/Deep_Learning/train/drums -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/train_sums/drums_$(basename \"$1\")\"' _ {} \\;"
      ],
      "metadata": {
        "id": "AZ21K-RPxVJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lfind /content/drive/MyDrive/Deep_Learning/train/bass -name \"*.wav\" -exec sh -c 'cp \"$1\" \"/content/drive/MyDrive/Deep_Learning/train_sums/bass_$(basename \"$1\")\"' _ {} \\;"
      ],
      "metadata": {
        "id": "2VAyV870GSBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mpiexec -n 1 python ./lass/train_sums.py --epochs=100  --vqvae-path=./logs/lq_vae/checkpoint_step_19160.pth.tar --audio-files-dir=../../train_sums  --output-dir=./logs/vqvae_sum_distribution --sample-length=5.944308 --sample-rate=22050 --save-iters=250"
      ],
      "metadata": {
        "id": "TsiAyxyjxYvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "F-sHfq7ZxfGE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This sequence of cells runs the evaluation of LQVAE-LASS-hybrid: from twenty mixtures a single chunk of three seconds is extracted, this chunk is then separated. To evaluate the results the generated sources are compared to the originals through Signal-to-Noise Ratio, this metric is used also in both papers of LASS and LQVAE.\n",
        "\n",
        "The lower results compared to the original can be attributed to the lower training time of the model, as said before the access to a GPU is restricted to three hours per day, this is the same reason why only twenty chunks were used to evaluate the model."
      ],
      "metadata": {
        "id": "2tMYm87hJ4oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mpiexec -n 1 python ./script/bayesian_test.py"
      ],
      "metadata": {
        "id": "lzMz5sPaOsPk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe9da00d-f061-4ad9-986f-5343e8547256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda True\n",
            "Restored from ./logs/lq_vae/checkpoint_step_19160.pth.tar\n",
            "0: Loading vqvae in eval mode\n",
            "Level:2, Cond downsample:None, Raw to tokens:64, Sample length:524288\n",
            "0: Converting to fp16 params\n",
            "Restored from ./logs/prior_drums/checkpoint_latest.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Level:2, Cond downsample:None, Raw to tokens:64, Sample length:524288\n",
            "0: Converting to fp16 params\n",
            "Restored from ./logs/prior_bass/checkpoint_latest.pth.tar\n",
            "0: Loading prior in eval mode\n",
            "Found 89 instances of instrument_1\n",
            "Found 89 instances of instrument_2\n",
            "available_chunks for ('Track00001_1.wav', 'Track00001_1.wav'): 1\n",
            "available_chunks for ('Track00002_2.wav', 'Track00002_2.wav'): 1\n",
            "available_chunks for ('Track00003_3.wav', 'Track00003_3.wav'): 1\n",
            "available_chunks for ('Track00004_4.wav', 'Track00004_4.wav'): 1\n",
            "available_chunks for ('Track00005_5.wav', 'Track00005_5.wav'): 1\n",
            "available_chunks for ('Track00006_6.wav', 'Track00006_6.wav'): 1\n",
            "available_chunks for ('Track00007_7.wav', 'Track00007_7.wav'): 1\n",
            "available_chunks for ('Track00008_8.wav', 'Track00008_8.wav'): 1\n",
            "available_chunks for ('Track00009_9.wav', 'Track00009_9.wav'): 1\n",
            "available_chunks for ('Track00010_10.wav', 'Track00010_10.wav'): 1\n",
            "available_chunks for ('Track00011_11.wav', 'Track00011_11.wav'): 1\n",
            "available_chunks for ('Track00012_12.wav', 'Track00012_12.wav'): 1\n",
            "available_chunks for ('Track00013_13.wav', 'Track00012_13.wav'): 1\n",
            "available_chunks for ('Track00014_14.wav', 'Track00013_14.wav'): 1\n",
            "available_chunks for ('Track00015_15.wav', 'Track00013_15.wav'): 1\n",
            "available_chunks for ('Track00016_16.wav', 'Track00014_16.wav'): 1\n",
            "available_chunks for ('Track00017_17.wav', 'Track00015_17.wav'): 1\n",
            "available_chunks for ('Track00019_19.wav', 'Track00018_19.wav'): 1\n",
            "available_chunks for ('Track00020_20.wav', 'Track00018_20.wav'): 1\n",
            "available_chunks for ('Track00021_21.wav', 'Track00019_21.wav'): 1\n",
            "available_chunks for ('Track00022_22.wav', 'Track00020_22.wav'): 1\n",
            "available_chunks for ('Track00023_23.wav', 'Track00023_23.wav'): 1\n",
            "available_chunks for ('Track00024_24.wav', 'Track00024_24.wav'): 1\n",
            "available_chunks for ('Track00025_25.wav', 'Track00024_25.wav'): 1\n",
            "available_chunks for ('Track00026_26.wav', 'Track00024_26.wav'): 1\n",
            "available_chunks for ('Track00027_27.wav', 'Track00025_27.wav'): 1\n",
            "available_chunks for ('Track00028_28.wav', 'Track00026_28.wav'): 1\n",
            "available_chunks for ('Track00029_29.wav', 'Track00027_29.wav'): 1\n",
            "available_chunks for ('Track00030_30.wav', 'Track00028_30.wav'): 1\n",
            "available_chunks for ('Track00031_31.wav', 'Track00028_31.wav'): 1\n",
            "available_chunks for ('Track00032_32.wav', 'Track00030_32.wav'): 1\n",
            "available_chunks for ('Track00033_33.wav', 'Track00031_33.wav'): 1\n",
            "available_chunks for ('Track00034_34.wav', 'Track00032_34.wav'): 1\n",
            "available_chunks for ('Track00035_35.wav', 'Track00033_35.wav'): 1\n",
            "available_chunks for ('Track00036_36.wav', 'Track00034_36.wav'): 1\n",
            "available_chunks for ('Track00037_37.wav', 'Track00035_37.wav'): 1\n",
            "available_chunks for ('Track00038_38.wav', 'Track00036_38.wav'): 1\n",
            "available_chunks for ('Track00039_39.wav', 'Track00037_39.wav'): 1\n",
            "available_chunks for ('Track00040_40.wav', 'Track00038_40.wav'): 1\n",
            "available_chunks for ('Track00041_41.wav', 'Track00039_41.wav'): 1\n",
            "available_chunks for ('Track00042_42.wav', 'Track00040_42.wav'): 1\n",
            "available_chunks for ('Track00043_43.wav', 'Track00040_43.wav'): 1\n",
            "available_chunks for ('Track00044_44.wav', 'Track00040_44.wav'): 1\n",
            "available_chunks for ('Track00045_45.wav', 'Track00040_45.wav'): 1\n",
            "available_chunks for ('Track00046_46.wav', 'Track00041_46.wav'): 1\n",
            "available_chunks for ('Track00047_47.wav', 'Track00042_47.wav'): 1\n",
            "available_chunks for ('Track00048_48.wav', 'Track00043_48.wav'): 1\n",
            "available_chunks for ('Track00050_49.wav', 'Track00043_49.wav'): 1\n",
            "available_chunks for ('Track00051_50.wav', 'Track00044_50.wav'): 1\n",
            "available_chunks for ('Track00052_51.wav', 'Track00045_51.wav'): 1\n",
            "available_chunks for ('Track00053_52.wav', 'Track00046_52.wav'): 1\n",
            "available_chunks for ('Track00054_53.wav', 'Track00046_53.wav'): 1\n",
            "available_chunks for ('Track00055_54.wav', 'Track00047_54.wav'): 1\n",
            "available_chunks for ('Track00056_55.wav', 'Track00048_55.wav'): 1\n",
            "available_chunks for ('Track00057_56.wav', 'Track00048_56.wav'): 1\n",
            "available_chunks for ('Track00058_57.wav', 'Track00050_57.wav'): 1\n",
            "available_chunks for ('Track00059_58.wav', 'Track00051_58.wav'): 1\n",
            "available_chunks for ('Track00060_59.wav', 'Track00052_59.wav'): 1\n",
            "available_chunks for ('Track00061_60.wav', 'Track00053_60.wav'): 1\n",
            "available_chunks for ('Track00062_61.wav', 'Track00054_61.wav'): 1\n",
            "available_chunks for ('Track00063_62.wav', 'Track00055_62.wav'): 1\n",
            "available_chunks for ('Track00064_63.wav', 'Track00059_63.wav'): 1\n",
            "available_chunks for ('Track00065_64.wav', 'Track00060_64.wav'): 1\n",
            "available_chunks for ('Track00066_65.wav', 'Track00061_65.wav'): 1\n",
            "available_chunks for ('Track00067_66.wav', 'Track00063_66.wav'): 1\n",
            "available_chunks for ('Track00068_67.wav', 'Track00064_67.wav'): 1\n",
            "available_chunks for ('Track00069_68.wav', 'Track00065_68.wav'): 1\n",
            "available_chunks for ('Track00070_69.wav', 'Track00066_69.wav'): 1\n",
            "available_chunks for ('Track00071_70.wav', 'Track00067_70.wav'): 1\n",
            "available_chunks for ('Track00072_71.wav', 'Track00068_71.wav'): 1\n",
            "available_chunks for ('Track00073_72.wav', 'Track00069_72.wav'): 1\n",
            "available_chunks for ('Track00074_73.wav', 'Track00071_73.wav'): 1\n",
            "available_chunks for ('Track00075_74.wav', 'Track00072_74.wav'): 1\n",
            "available_chunks for ('Track00076_75.wav', 'Track00073_75.wav'): 1\n",
            "available_chunks for ('Track00078_76.wav', 'Track00074_76.wav'): 1\n",
            "available_chunks for ('Track00079_77.wav', 'Track00074_77.wav'): 1\n",
            "available_chunks for ('Track00080_78.wav', 'Track00074_78.wav'): 1\n",
            "available_chunks for ('Track00081_79.wav', 'Track00075_79.wav'): 1\n",
            "available_chunks for ('Track00082_80.wav', 'Track00076_80.wav'): 1\n",
            "available_chunks for ('Track00083_81.wav', 'Track00078_81.wav'): 1\n",
            "available_chunks for ('Track00084_82.wav', 'Track00079_82.wav'): 1\n",
            "available_chunks for ('Track00085_83.wav', 'Track00079_83.wav'): 1\n",
            "available_chunks for ('Track00086_84.wav', 'Track00080_84.wav'): 1\n",
            "available_chunks for ('Track00087_85.wav', 'Track00081_85.wav'): 1\n",
            "available_chunks for ('Track00088_86.wav', 'Track00082_86.wav'): 1\n",
            "available_chunks for ('Track00089_87.wav', 'Track00082_87.wav'): 1\n",
            "available_chunks for ('Track00090_88.wav', 'Track00083_88.wav'): 1\n",
            "available_chunks for ('Track00091_89.wav', 'Track00084_89.wav'): 1\n",
            "available_chunks for ('Track00092_90.wav', 'Track00085_90.wav'): 1\n",
            "chunk 1 out of 89\n",
            "1024/1024 [02:26<00:00,  6.99it/s]/usr/local/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
            "  '\"sox\" backend is being deprecated. '\n",
            "/usr/local/lib/python3.7/site-packages/sparse/_umath.py:542: RuntimeWarning: divide by zero encountered in log\n",
            "  *np.broadcast_arrays(*zero_args), dtype=self.dtype, **self.kwargs\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:00<00:00, 88.28it/s]\n",
            "SDR GT: sdr0=8.185836791992188, sdr1=6.090103626251221\n",
            "SDR REAL: sdr0=7.782161712646484, sdr1=6.3330397605896\n",
            "chunk 2 out of 89\n",
            "1024/1024 [02:13<00:00,  7.67it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:00<00:00, 86.80it/s]\n",
            "SDR GT: sdr0=4.802060127258301, sdr1=4.7514824867248535\n",
            "SDR REAL: sdr0=4.927928924560547, sdr1=4.651514530181885\n",
            "chunk 3 out of 89\n",
            "1024/1024 [02:16<00:00,  7.52it/s]\n",
            "Rejection sampling: 100%|██████████| 64/64 [00:00<00:00, 84.53it/s]\n",
            "SDR GT: sdr0=4.1028523445129395, sdr1=5.208760738372803\n",
            "SDR REAL: sdr0=3.9767792224884033, sdr1=4.973168849945068\n",
            "chunk 4 out of 89\n",
            "149/1024 [00:21<01:52,  7.77it/s][mpiexec@aa44cf27125e] Sending Ctrl-C to processes as requested\n",
            "[mpiexec@aa44cf27125e] Press Ctrl-C again to force abort\n",
            "Ctrl-C caught... cleaning up processes\n",
            "[proxy:0:0@aa44cf27125e] HYD_pmcd_pmip_control_cmd_cb (pm/pmiserv/pmip_cb.c:878): assert (!closed) failed\n",
            "[proxy:0:0@aa44cf27125e] HYDT_dmxu_poll_wait_for_event (tools/demux/demux_poll.c:77): callback returned error status\n",
            "[proxy:0:0@aa44cf27125e] main (pm/pmiserv/pmip.c:200): demux engine error waiting for event\n",
            "[mpiexec@aa44cf27125e] HYDT_bscu_wait_for_completion (tools/bootstrap/utils/bscu_wait.c:75): one of the processes terminated badly; aborting\n",
            "[mpiexec@aa44cf27125e] HYDT_bsci_wait_for_completion (tools/bootstrap/src/bsci_wait.c:22): launcher returned error waiting for completion\n",
            "[mpiexec@aa44cf27125e] HYD_pmci_wait_for_completion (pm/pmiserv/pmiserv_pmci.c:215): launcher returned error waiting for completion\n",
            "[mpiexec@aa44cf27125e] main (ui/mpich/mpiexec.c:336): process manager error waiting for completion\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SGsfe6-R45lk",
        "NV042DIGAVpA",
        "H_8iYMABo6BU",
        "-DsbUyKboVi8",
        "v8ZULaz49_pZ",
        "LDRkyAGrVTFO",
        "2SEpGBTfS0bJ",
        "4hvLuSwSAZtq",
        "oU99GCbVbVvk",
        "1Yqik3NoPQNH",
        "61VAmOIqPTlf",
        "LADQI63vPns3",
        "aYttTqpFPrY4",
        "UjWlTC6S9065",
        "G4yIJmvhOpxm",
        "Cbx5OjfyxdKe",
        "F-sHfq7ZxfGE"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}